{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets from Hugging Face\n",
    "\n",
    "Import datasets from Hugging Face Hub directly into Pixeltable tables.\n",
    "\n",
    "**What's in this recipe:**\n",
    "- Import Hugging Face datasets with one function call\n",
    "- Automatic schema inference from dataset structure  \n",
    "- Work with audio files in Pixeltable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "Hugging Face hosts thousands of multimodal datasets including audio. You need these datasets in Pixeltable to apply AI models, create embeddings, or run analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "**What's in this recipe:**\n",
    "- Import Hugging Face datasets with one function call\n",
    "- Automatic schema inference from dataset structure\n",
    "- Work with audio classification datasets in Pixeltable\n",
    "\n",
    "You import Hugging Face datasets directly into Pixeltable tables using `pxt.create_table()` with the `source` parameter. This automatically infers the schema and loads the data, where you can immediately apply AI models and query results.\n",
    "\n",
    "You can iterate on transformations before adding them to your table. Use `.select()` with `.collect()` to preview results on sample dataâ€”nothing is stored in your table. If you want to collect only the first few rows, use `.head(n)` instead of `.collect()`. Once you're satisfied, use `.add_computed_column()` to apply transformations to all rows in your table.\n",
    "\n",
    "For more on this workflow, see [Get fast feedback on transformations](./dev-iterative-workflow.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv add pixeltable datasets torchcodec twelvelabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixeltable as pxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the [Drone Audio Detection Samples](https://huggingface.co/datasets/geronimobasso/drone-audio-detection-samples) dataset from Hugging Face, as described in the [Hugging Face documentation](https://huggingface.co/docs/datasets/en/package_reference/loading_methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "drone_audio = datasets.load_dataset(\n",
    "    'geronimobasso/drone-audio-detection-samples',\n",
    "    split='train'\n",
    ").cast_column('audio', datasets.Audio(decode=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pixeltable table\n",
    "\n",
    "Now create a table and Pixeltable will map column types as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the audio file paths\n",
    "pxt.drop_dir('drone_audio', force=True)\n",
    "pxt.create_dir('drone_audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pxt.create_table(\n",
    "    'drone_audio.samples',\n",
    "    schema={\n",
    "        'audio': pxt.Audio,\n",
    "        'label': pxt.Int\n",
    "    },\n",
    "    comment='Drone audio detection samples with binary classification labels (drone vs non-drone) from Hugging Face'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract audio bytes\n",
    "rows = []\n",
    "for item in drone_audio:\n",
    "    row = dict(item)\n",
    "    row['audio'] = item['audio']['bytes']  # Use the bytes\n",
    "    rows.append(row)\n",
    "\n",
    "t.insert(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sample data\n",
    "t.select(t.audio, t.label).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total count\n",
    "t.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Audio Metadata\n",
    "\n",
    "Add computed columns to extract metadata from the audio files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract audio metadata\n",
    "t.add_computed_column(metadata=t.audio.get_metadata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract duration in seconds from metadata\n",
    "t.add_computed_column(\n",
    "    duration_seconds=t.metadata['streams'][0]['duration_seconds']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the metadata\n",
    "t.select(t.audio, t.label, t.duration_seconds).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish to Pixeltable Cloud\n",
    "\n",
    "Publish the table to make it available on Pixeltable Cloud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publish the table to Pixeltable Cloud\n",
    "pxt.publish(\n",
    "    'drone_audio.samples',\n",
    "    'pxt://pixeltable:hugging-face/drone_audio',\n",
    "    access='public'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Audio Embeddings (Optional)\n",
    "\n",
    "Add audio embeddings using TwelveLabs for audio similarity search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixeltable.functions import twelvelabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "# Set TwelveLabs API key for audio embeddings\n",
    "os.environ['TWELVELABS_API_KEY'] = getpass('TwelveLabs API Key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add TwelveLabs audio embeddings for similarity search\n",
    "# Pixeltable handles the embedding computation automatically\n",
    "t.add_embedding_index(\n",
    "    'audio',\n",
    "    embedding=twelvelabs.embed.using(\n",
    "        model_name='Marengo-retrieval-2.7'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See also\n",
    "\n",
    "- [Drone Audio Detection Dataset on Hugging Face](https://huggingface.co/datasets/geronimobasso/drone-audio-detection-samples)\n",
    "- [Working with Audio in Pixeltable](https://docs.pixeltable.com/docs/working-with-audio)\n",
    "- [TwelveLabs Integration](https://docs.pixeltable.com/api/functions/twelvelabs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pxt-cloud-sets)",
   "language": "python",
   "name": "pxt-cloud-sets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
